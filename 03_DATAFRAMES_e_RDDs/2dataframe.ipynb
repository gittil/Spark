{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe\n",
    "\n",
    "- Tabelas com linhas e colunas\n",
    "- Imutaveis\n",
    "- Com schema conhecido\n",
    "- Linhagem preservada\n",
    "- Colunas podem ter tipos diferentes\n",
    "- Existem analises comuns: Agrupar, ordenar,filtrar\n",
    "- Spark pode otimizar estas analises atraves de planos de execucao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lazy Evaluetion\n",
    "- O processamento de transformacao de fato so ocorre quando ha uma açao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schema\n",
    "- Voce pode deixar para o Spark inferir a partir de parte dos dados\n",
    "- Ou voce pode definir o schema\n",
    "\n",
    "Definir tem vantagens:\n",
    "- Tipo correto\n",
    "- Sem overhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importando o pyspark e outros modulos necessarios\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iniciando uma Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "        .appName(\"RDD\") \\\n",
    "            .config(\"spark.executer.memory\",\"1gb\") \\\n",
    "                .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criando um dataframe passando um conjunto de dados sem schema\n",
    "df1 = spark.createDataFrame([(\"Pedro\",10),(\"Maria\",20),(\"Jose\", 40)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "|   _1| _2|\n",
      "+-----+---+\n",
      "|Pedro| 10|\n",
      "|Maria| 20|\n",
      "| Jose| 40|\n",
      "+-----+---+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criando um dataframe com schema\n",
    "schema = \"Id INT, Nome STRING\"\n",
    "dados = [[1,\"Pedro\"],[2,\"Maria\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.createDataFrame(dados,schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| Id| Nome|\n",
      "+---+-----+\n",
      "|  1|Pedro|\n",
      "|  2|Maria|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformacoes iniciais com Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema2 = \"Produtos STRING, Vendas INT\"\n",
    "vendas = [[\"Caneta\",10],[\"Lapis\",20],[\"Caneta\",40]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|Produtos|Vendas|\n",
      "+--------+------+\n",
      "|  Caneta|    10|\n",
      "|   Lapis|    20|\n",
      "|  Caneta|    40|\n",
      "+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = spark.createDataFrame(vendas,schema2)\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|Produtos|sum(Vendas)|\n",
      "+--------+-----------+\n",
      "|  Caneta|         50|\n",
      "|   Lapis|         20|\n",
      "+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#agregacao\n",
    "agrupado = df3.groupBy(\"Produtos\").agg(sum(\"Vendas\"))\n",
    "agrupado.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|Produtos|\n",
      "+--------+\n",
      "|  Caneta|\n",
      "|   Lapis|\n",
      "|  Caneta|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#selecionando quais colunas mostrar\n",
    "df3.select(\"Produtos\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+--------------+\n",
      "|Produtos|Vendas|(Vendas * 0.2)|\n",
      "+--------+------+--------------+\n",
      "|  Caneta|    10|           2.0|\n",
      "|   Lapis|    20|           4.0|\n",
      "|  Caneta|    40|           8.0|\n",
      "+--------+------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#criando expressoes (calculo)\n",
    "df3.select(\"Produtos\",\"Vendas\",expr(\"Vendas * 0.2\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(Produtos,StringType,true),StructField(Vendas,IntegerType,true)))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualizando o schema do dataframe\n",
    "df3.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Produtos', 'Vendas']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualizando as colunas do dataframe\n",
    "df3.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ingerindo dados atraves de um arquivo CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criando o schema\n",
    "arqschema = \"id INT, nome STRING, status STRING, cidade STRING, vendas INT, data STRING\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lendo o arquivo csv e inferindo o schema criado\n",
    "despachantes = spark.read.csv(\"/home/douglas/download/despachantes.csv\",header=False, schema=arqschema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+------+-------------+------+----------+\n",
      "| id|               nome|status|       cidade|vendas|      data|\n",
      "+---+-------------------+------+-------------+------+----------+\n",
      "|  1|   Carminda Pestana| Ativo|  Santa Maria|    23|2020-08-11|\n",
      "|  2|    Deolinda Vilela| Ativo|Novo Hamburgo|    34|2020-03-05|\n",
      "|  3|   Emídio Dornelles| Ativo| Porto Alegre|    34|2020-02-05|\n",
      "|  4|Felisbela Dornelles| Ativo| Porto Alegre|    36|2020-02-05|\n",
      "|  5|     Graça Ornellas| Ativo| Porto Alegre|    12|2020-02-05|\n",
      "|  6|   Matilde Rebouças| Ativo| Porto Alegre|    22|2019-01-05|\n",
      "|  7|    Noêmia   Orriça| Ativo|  Santa Maria|    45|2019-10-05|\n",
      "|  8|      Roque Vásquez| Ativo| Porto Alegre|    65|2020-03-05|\n",
      "|  9|      Uriel Queiroz| Ativo| Porto Alegre|    54|2018-05-05|\n",
      "| 10|   Viviana Sequeira| Ativo| Porto Alegre|     0|2020-09-05|\n",
      "+---+-------------------+------+-------------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "despachantes.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carregando o arquivo csv com outra funcao, a load\n",
    "#nessa funcao temos que informar o tipo do arquivo\n",
    "#nessa carga deixaremos o spark avaliar os dados e inferir o schema\n",
    "desp_autoschema = spark.read.load(\"/home/douglas/download/despachantes.csv\",header=False,format=\"csv\", sep=\",\", inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+-----+-------------+---+----------+\n",
      "|_c0|                _c1|  _c2|          _c3|_c4|       _c5|\n",
      "+---+-------------------+-----+-------------+---+----------+\n",
      "|  1|   Carminda Pestana|Ativo|  Santa Maria| 23|2020-08-11|\n",
      "|  2|    Deolinda Vilela|Ativo|Novo Hamburgo| 34|2020-03-05|\n",
      "|  3|   Emídio Dornelles|Ativo| Porto Alegre| 34|2020-02-05|\n",
      "|  4|Felisbela Dornelles|Ativo| Porto Alegre| 36|2020-02-05|\n",
      "|  5|     Graça Ornellas|Ativo| Porto Alegre| 12|2020-02-05|\n",
      "|  6|   Matilde Rebouças|Ativo| Porto Alegre| 22|2019-01-05|\n",
      "|  7|    Noêmia   Orriça|Ativo|  Santa Maria| 45|2019-10-05|\n",
      "|  8|      Roque Vásquez|Ativo| Porto Alegre| 65|2020-03-05|\n",
      "|  9|      Uriel Queiroz|Ativo| Porto Alegre| 54|2018-05-05|\n",
      "| 10|   Viviana Sequeira|Ativo| Porto Alegre|  0|2020-09-05|\n",
      "+---+-------------------+-----+-------------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "desp_autoschema.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(id,IntegerType,true),StructField(nome,StringType,true),StructField(status,StringType,true),StructField(cidade,StringType,true),StructField(vendas,IntegerType,true),StructField(data,StringType,true)))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#temos que verificar se o spark fez a inferencia do esquema corretamente\n",
    "despachantes.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(_c0,IntegerType,true),StructField(_c1,StringType,true),StructField(_c2,StringType,true),StructField(_c3,StringType,true),StructField(_c4,IntegerType,true),StructField(_c5,StringType,true)))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desp_autoschema.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicando fitros com clausula WHERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as Func \n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+------+\n",
      "| id|               nome|vendas|\n",
      "+---+-------------------+------+\n",
      "|  1|   Carminda Pestana|    23|\n",
      "|  2|    Deolinda Vilela|    34|\n",
      "|  3|   Emídio Dornelles|    34|\n",
      "|  4|Felisbela Dornelles|    36|\n",
      "|  6|   Matilde Rebouças|    22|\n",
      "|  7|    Noêmia   Orriça|    45|\n",
      "|  8|      Roque Vásquez|    65|\n",
      "|  9|      Uriel Queiroz|    54|\n",
      "+---+-------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#passando um filtro com clausula WHERE aplicada na coluna Vendas\n",
    "despachantes.select(\"id\",\"nome\",\"vendas\").where(Func.col(\"Vendas\") > 20).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Operadores logicos:\n",
    "- & = AND\n",
    "- | = OR\n",
    "- ~ = NOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+------+\n",
      "| id|               nome|vendas|\n",
      "+---+-------------------+------+\n",
      "|  1|   Carminda Pestana|    23|\n",
      "|  2|    Deolinda Vilela|    34|\n",
      "|  3|   Emídio Dornelles|    34|\n",
      "|  4|Felisbela Dornelles|    36|\n",
      "|  6|   Matilde Rebouças|    22|\n",
      "+---+-------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#fazendo uma consulta com clausula WHERE e operador logico AND\n",
    "despachantes.select(\"id\",\"nome\",\"vendas\").\\\n",
    "    where((Func.col(\"Vendas\") > 20) & (Func.col(\"Vendas\") < 40)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Manipulando colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'nomes', 'status', 'cidade', 'vendas', 'data']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#alterando o nome da coluna\n",
    "novodf = despachantes.withColumnRenamed(\"nome\",\"nomes\")\n",
    "novodf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alterando o tipo da coluna\n",
    "# necessario crirar uma nova coluna informando qual o tipo e qual a coluna que ela ira se basear\n",
    "despachantes2 = despachantes.withColumn(\"data2\",to_timestamp(Func.col(\"data\"),\"yyyy-MM-dd\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(id,IntegerType,true),StructField(nome,StringType,true),StructField(status,StringType,true),StructField(cidade,StringType,true),StructField(vendas,IntegerType,true),StructField(data,StringType,true),StructField(data2,TimestampType,true)))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "despachantes2.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|year(data)|\n",
      "+----------+\n",
      "|      2018|\n",
      "|      2019|\n",
      "|      2020|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#usando funcao de data\n",
    "despachantes2.select(year(\"data\"))\\\n",
    "    .distinct()\\\n",
    "        .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+\n",
      "|               nome|year(data)|\n",
      "+-------------------+----------+\n",
      "|   Carminda Pestana|      2020|\n",
      "|    Deolinda Vilela|      2020|\n",
      "|   Emídio Dornelles|      2020|\n",
      "|Felisbela Dornelles|      2020|\n",
      "|     Graça Ornellas|      2020|\n",
      "|   Matilde Rebouças|      2019|\n",
      "|    Noêmia   Orriça|      2019|\n",
      "|      Roque Vásquez|      2020|\n",
      "|      Uriel Queiroz|      2018|\n",
      "|   Viviana Sequeira|      2020|\n",
      "+-------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#concatenando comandos\n",
    "despachantes2.select(\"nome\",year(\"data\"))\\\n",
    "    .orderBy(\"nome\")\\\n",
    "        .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|year(data)|count|\n",
      "+----------+-----+\n",
      "|      2018|    1|\n",
      "|      2019|    2|\n",
      "|      2020|    7|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "despachantes2.select(\"data\").groupBy(year(\"data\")).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|sum(vendas)|\n",
      "+-----------+\n",
      "|        325|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "despachantes2.select(Func.sum(\"vendas\")).show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
